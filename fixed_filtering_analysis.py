#!/usr/bin/env python3
"""
Fixed Detailed Filtering Analysis Script

RNAViewã¨DSSRã®è§£æçµæœã‚’æ­£ã—ãæ¯”è¼ƒåˆ†æã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import json
from pathlib import Path
from collections import Counter

def analyze_parser_results(json_file, description, initial_chain_count):
    """å„ãƒ‘ãƒ¼ã‚µãƒ¼ã®çµæœã‚’åˆ†æ"""
    
    if not Path(json_file).exists():
        print(f"âŒ {description}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ ({json_file})")
        return None
    
    with open(json_file, 'r') as f:
        results = json.load(f)
    
    print(f"ğŸ“Š ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ãƒ•ãƒ­ãƒ¼åˆ†æ ({description})")
    print("-" * 80)
    
    # Step 1: åˆæœŸãƒ•ã‚¡ã‚¤ãƒ«æ•°
    print(f"Step 1 - åˆæœŸPDBãƒ•ã‚¡ã‚¤ãƒ«æ•°: {initial_chain_count}")
    
    # Step 2: å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°
    processed_count = len(results)
    removed_files = initial_chain_count - processed_count
    print(f"Step 2 - å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {processed_count} (é™¤å¤–: {removed_files})")
    
    # Step 3: è§£ææˆåŠŸã®åˆ¤å®š
    # output_existsãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹å ´åˆï¼ˆDSSRï¼‰ã¨ãªã„å ´åˆï¼ˆRNAViewï¼‰ã§åˆ¤å®šæ–¹æ³•ã‚’å¤‰ãˆã‚‹
    if results and 'output_exists' in results[0]:
        # DSSRã®å ´åˆ
        successful_analyses = [r for r in results if r.get('output_exists', False)]
        success_criteria = "output_exists=True"
    else:
        # RNAViewã®å ´åˆï¼štotal_bp_countãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’æˆåŠŸã¨ã™ã‚‹
        successful_analyses = [r for r in results if 'total_bp_count' in r]
        success_criteria = "total_bp_count ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å­˜åœ¨"
    
    analysis_failures = processed_count - len(successful_analyses)
    print(f"Step 3 - è§£ææˆåŠŸ: {len(successful_analyses)} (å¤±æ•—: {analysis_failures})")
    print(f"         åˆ¤å®šåŸºæº–: {success_criteria}")
    
    # Step 4: å¡©åŸºå¯¾ãŒè¦‹ã¤ã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«
    chains_with_basepairs = [r for r in results if r.get('total_bp_count', 0) > 0]
    no_basepairs = len(successful_analyses) - len(chains_with_basepairs)
    print(f"Step 4 - å¡©åŸºå¯¾ç™ºè¦‹: {len(chains_with_basepairs)} (å¡©åŸºå¯¾ãªã—: {no_basepairs})")
    
    # åŸºæœ¬çµ±è¨ˆ
    analyze_basic_stats(results, chains_with_basepairs, description)
    
    # ä¿æŒç‡è¨ˆç®—
    retention_rate = len(chains_with_basepairs) / initial_chain_count * 100
    print(f"æœ€çµ‚ä¿æŒç‡: {retention_rate:.1f}%")
    print()
    
    return {
        'processed_count': processed_count,
        'successful_count': len(successful_analyses),
        'basepair_count': len(chains_with_basepairs),
        'results': results,
        'chains_with_basepairs': chains_with_basepairs
    }

def analyze_basic_stats(results, chains_with_basepairs, description):
    """åŸºæœ¬çµ±è¨ˆã®åˆ†æ"""
    
    # ç•°å¸¸ãƒšã‚¢çµ±è¨ˆ
    if results:
        chains_with_abnormal = len([r for r in results if r.get('abnormal_pairs', [])])
        chains_with_duplicates = len([r for r in results if r.get('dup_canonical_pairs', [])])
        
        total_abnormal = sum(len(r.get('abnormal_pairs', [])) for r in results)
        total_duplicates = sum(len(r.get('dup_canonical_pairs', [])) for r in results)
        
        print(f"ç•°å¸¸ãªå¡©åŸºå¯¾ãŒæ¤œå‡ºã•ã‚ŒãŸãƒã‚§ãƒ¼ãƒ³æ•°: {chains_with_abnormal}")
        print(f"é‡è¤‡canonicalå¡©åŸºå¯¾ãŒæ¤œå‡ºã•ã‚ŒãŸãƒã‚§ãƒ¼ãƒ³æ•°: {chains_with_duplicates}")
        print(f"ç·ç•°å¸¸ãƒšã‚¢æ•°: {total_abnormal}")
        print(f"ç·é‡è¤‡canonicalãƒšã‚¢æ•°: {total_duplicates}")
    
    # å¡©åŸºå¯¾æ•°çµ±è¨ˆ
    if chains_with_basepairs:
        bp_counts = [r['total_bp_count'] for r in chains_with_basepairs]
        canonical_bp_counts = [r.get('total_canonical_bp_count', 0) for r in chains_with_basepairs]
        
        print(f"å¹³å‡å¡©åŸºå¯¾æ•°: {sum(bp_counts) / len(bp_counts):.1f}")
        print(f"å¹³å‡canonicalå¡©åŸºå¯¾æ•°: {sum(canonical_bp_counts) / len(canonical_bp_counts):.1f}")
        print(f"æœ€å¤§å¡©åŸºå¯¾æ•°: {max(bp_counts)}")
        print(f"æœ€å°å¡©åŸºå¯¾æ•°: {min(bp_counts)}")

def detailed_filtering_analysis():
    """ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚¹ãƒ†ãƒƒãƒ—ã®è©³ç´°åˆ†æ"""
    
    # åˆæœŸãƒ‡ãƒ¼ã‚¿
    dataset_dir = Path("analysis/datasets/BGSU__M__All__A__4_0__pdb_3_396")
    pdb_files = list(dataset_dir.glob("*.pdb"))
    initial_chain_count = len(pdb_files)
    
    print("=" * 80)
    print("ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°è©³ç´°åˆ†æ (ä¿®æ­£ç‰ˆ)")
    print("=" * 80)
    print(f"åˆæœŸPDBãƒ•ã‚¡ã‚¤ãƒ«æ•°: {initial_chain_count}")
    print()
    
    # è§£æçµæœãƒ•ã‚¡ã‚¤ãƒ«ã‚’åˆ†æ
    analysis_files = [
        ("analysis/pseudoknot_analysis_dssr_all.json", "DSSR (All)"),
        ("analysis/pseudoknot_analysis_rnaview_all.json", "RNAView (All)"),
        ("analysis/pseudoknot_analysis_dssr_canonical_only.json", "DSSR (Canonical Only)"),
        ("analysis/pseudoknot_analysis_rnaview_canonical_only.json", "RNAView (Canonical Only)")
    ]
    
    results_summary = {}
    
    for json_file, description in analysis_files:
        result = analyze_parser_results(json_file, description, initial_chain_count)
        if result:
            results_summary[description] = result
    
    # æ¯”è¼ƒåˆ†æ
    print("ğŸ” ãƒ‘ãƒ¼ã‚µãƒ¼æ¯”è¼ƒåˆ†æ")
    print("=" * 80)
    
    if "DSSR (All)" in results_summary and "RNAView (All)" in results_summary:
        dssr_result = results_summary["DSSR (All)"]
        rnaview_result = results_summary["RNAView (All)"]
        
        print("DSSRã¨RNAViewã®æ¯”è¼ƒ:")
        print(f"DSSR   - å‡¦ç†æˆåŠŸ: {dssr_result['successful_count']}, å¡©åŸºå¯¾ç™ºè¦‹: {dssr_result['basepair_count']}")
        print(f"RNAView - å‡¦ç†æˆåŠŸ: {rnaview_result['successful_count']}, å¡©åŸºå¯¾ç™ºè¦‹: {rnaview_result['basepair_count']}")
        
        # ãªãœRNAViewã®è§£ææˆåŠŸæ•°ãŒ0ã ã£ãŸã‹ã®èª¬æ˜
        print("\nğŸ’¡ RNAViewã§è§£ææˆåŠŸæ•°ãŒ0ã ã£ãŸç†ç”±:")
        print("- DSSRã®çµæœã«ã¯output_existsãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚Šã€ã“ã‚Œã§è§£ææˆåŠŸã‚’åˆ¤å®š")
        print("- RNAViewã®çµæœã«ã¯output_existsãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãªã„")
        print("- ä¿®æ­£å¾Œã¯ã€total_bp_countãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ã§è§£ææˆåŠŸã‚’åˆ¤å®š")

if __name__ == "__main__":
    detailed_filtering_analysis()
